## なぜVMからkubernetesに移行したのか

いちいちVMを手動構築するため、開発環境をすぐに用意できない。各環境再現性を担保できない

そこで開発環境をコンテナに

- 協力会社がVM
- コンテナイメージあればすぐに構築でき、開発環境構築時間を大幅に削減
- 開発環境の再現性を十分に担保できる
- オーケストレーションするためkubenetes

## VM時代

- 他案件掛け持ちながらVM作成、手順書通り構築、手順書で間違いがあれば修正
- spring,InteliJ,CICDはJenkinsもVMで構築されていた

### コンテナ化へ

- コンテナでデスクトップ環境をこうちくするためKasmを使用
- KasmはOSSとして公開しているDockerイメージ
- VNCが構築済みのイメージ
- Dockerfileを自由うにカスタマイズすることも可能。
- Dockerfileを開発チーム自身でGit管理するようにした。
- CI/CDJenkins自体のコンテナ化は不要。
    - Helm Chartでパッケージングされている。
    - Jenkinsをhelmチャートでinstall
    - Kubernetes Plugin Jenkins Plugin

## コンテナ後

### 構築作業はmanifest apply で構築が簡単に

## 良かったこと

- 構築にかかる時間を80$削減
- 人的エラーを解消し、再現性を向上
- 責任分界点の偏りを解消
    - クラスターとネットワーク管理は運用チームが責任もつ
    - 環境構築ようのDOckerfileはかく開発チームがもつ
- AWSの利用料の削減
    - 月額利用料の約15%削減

## しばらくコンテナで運用していると。。

- 開発環境の動作が全体的にもっさりしている
- Jenkins Jobgaなかなか始まらない　などの問題点が

### 何がおこっていたのか?

- 1部のpodが大きなリソースを消費していたため。
    - javaのメモリリソース
    - worker node上でjava以外も立てていたため

### 1クラスターに全部いれている

### とりあえず

- ワーカーノード上のノード数上か
- ワーカーノード上スペック向上

### 根本解決ではないため。

- 新たな課題
    - 特定の高負荷podがクラスター全体の安定性に影響を与えてしまう
    - k8sバージョンアップが行いづらい
        - 各チームへのお伺いが必要
        - 全てのチームの足並みを揃えざるおえない
        

## せっかくk8sなのに運用がモノリスになっている

- クラスターの責務を分散する必要がある
    - クラスター分割する必要ある

## クラスター分割

- クラスターをどの単位で分割するか重要
- 開発チームごと、CICD基盤などで分割した
    - k8sのバージョンアップも核開発チームごとに分割できるようになった

### 複数クラスターを管理は大変ではないか

- k8sクラスターを管理できるOSSプラットフォーム Ranche導入
    - helmチャートカタログによるアプリのGUI管理
    - アプリ無停止でk8sバージョンアップ
    - グループ化したクラスターへの共通的な理スースの作成
    

 Ranche導入して良かったこと

- カタログGUIで簡単
- k8sバージョンアップが容易
